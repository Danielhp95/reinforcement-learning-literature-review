\documentclass{article}

\usepackage[a4paper,margin=1in,footskip=0.25in]{geometry} % sets margins
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{graphicx}
\usepackage{amssymb} % For maths symbols like real number R.
\usepackage{amsmath}
\usepackage{mathtools}
\usepackage[ruled, linesnumbered]{algorithm2e}

\DeclareMathOperator*{\argmax}{argmax}
\usepackage[round]{natbib}

\graphicspath{{images/}{../images/}}

\usepackage{subfiles}

% \usepackage{blindtext}

\title{\textbf{Literature review: Reinforcement Learning}}
\author{Daniel Hernandez}
\date{ }

\begin{document}

\maketitle

\tableofcontents

% \subfile{sections/abstract}
% 
\section{Introduction}
%\subfile{sections/introduction}

    \subsection{Markov Decision Processes}\label{section:markov-decision-processes}
    \subfile{sections/markov-decision-process}

    \subsection{Categorization of RL algorithms}
    \subfile{sections/reinforcement-learning-algorithms}
    
    %\subsection{Value Iteration algorithm}
    %\subfile{value-iteration}
    
\section{Q-learning}\label{section:q-learning}
\subfile{sections/q-learning}
 
\section{Policy gradient methods}\label{section:policy-gradient-methods}
\subfile{sections/policy-gradient-methods}
  
\section{Multi-agent reinforcement learning}
\subfile{sections/multiagent}

\section{Learning Environments}
\subfile{sections/learning-environments}

\section{Appendix}
\subfile{sections/likelihood-ratio-policy-gradient-derivation}

\bibliographystyle{apalike}
\bibliography{main}

\end{document}
